Avery Brown (amb222)

Run WordGramDiver for wordgrams of size 2-10 and record
the number of WordGram values/objects that occur more than
once as reported by the runs. For example, with WSIZE = 2,
which generates 2-grams, the output of benchmark and benchmarkShift
each indicates that the total # wordgrams generated is 177,634
and that the # unique wordgrams is 117,181

This means there are 177,634 - 117,181 = 60,453 WordGram values that
occur more than once. Find these same values for other orders
of k and complete the table below for different k-grams/different 
values of WSIZE

WSIZE    # duplicates
2        60,453
3        10,756
4		  1,987
5		 	667
6			340
7			226
8			151
9			105
10			 73

=====
Explain in your own words the conceptual differences between 
the benchmark and benchmarkShift methods. 
Answer these questions: 

(1) Why the results of these methods should be the same in 
terms of changes made to the HashSet parameter.

The results should be the same because both methods accurately form
wordgrams that are subsequently added to the hashset parameter.

(2) What are the conceptual differences between the two
benchmarking methods

The first benchmarking method adds all the words to an ArrayList and then
converts the ArrayList into an Array so that the wordgrams can be formed 
and added to the hashset parameter.
The second benchmarking method adds all the words into an Array, and
then adds the wordgram to the hashset parameter through a while loop.


(3) Is the total amount of memory allocated for arrays
the same or different in the two methods? Account for
arrays created in the methods and arrays created by
WordGram objects. Try to be quantitative in answering.

Method 1 creates more wordgram objects than Method 2 since the wordgram call is within 
a for loop Also, Method 2 creates an array size of w.size while method 1 creates an array size of 
all the words in the file so the amount of memory allocated for array 1 is much greater (probably by a factor
of myWords.length / w.size)


